---
title: "p8105_hw2_zz3166"
author: "Zihan Zhao"
date: "2024-10-02"
output: github_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Problem 0

```{r load_libraries}
library(tidyverse)
library(readxl)
library(dplyr)
```

### Problem 1

Data Import and Cleaning

```{r}
library(tidyverse)
library(readr)
library(janitor)

trans_ent = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) |> 
  janitor::clean_names() |> 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) |> 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

Dataset Description

The cleaned dataset contains information about subway station entrances and exits in New York City. It includes the following variables:

- **line**: Subway line where the station is located.
- **station_name**: Name of the station.
- **station_latitude** and **station_longitude**: Geographic coordinates of the station.
- **route1** to **route11**: Subway routes that serve the station.
- **entry**: Logical indicator of whether the entrance allows entry (`TRUE`) or not (`FALSE`).
- **vending**: Indicates if there are vending machines (`YES`/`NO`).
- **entrance_type**: Type of the entrance (e.g., `STAIR`, `ELEVATOR`).
- **ada**: Logical indicator of ADA compliance (`TRUE` if compliant).


```{r}
trans_ent |> 
  select(station_name, line) |> 
  distinct()
```
- **Answer**: There are **465** distinct stations in the street.

```{r}
trans_ent |> 
  filter(ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```
- **Answer**: There are **84** ADA compliant stations.

```{r}
trans_ent |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()
```

- **Answer**: Approximately **0.377** (37.7%) of station entrances/exits without vending allow entry.


Stations serving the A train and ADA Compliance

```{r}
trans_ent |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct()
```

- **Answer**:There are **60** distinct stations that serve the A train.

```{r}
trans_ent |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

- **Answer**: There are **17** ADA compliant stations that serve the A train.


### Problem 2

Import `Mr_Trashwheel` dataset. 
```{r}
Mr_Trashwheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(sports_balls = as.integer(round(sports_balls, 0)),
         source = "Mr. Trash Wheel")
```

Import `Professor_Trashwheel` dataset. 
```{r}
Professor_Trashwheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  select(dumpster, month, year, date, weight_tons , volume_cubic_yards,
         plastic_bottles, polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers, homes_powered) |> 
  mutate(year = as.character(year),  # Convert year to character for consistency
         source = "Professor Trash Wheel")
```

Import `Gwynnda_Trashwheel` dataset. 
```{r}
Gwynnda_Trashwheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  select(dumpster, month, year, date, weight_tons, volume_cubic_yards,
         plastic_bottles, polystyrene, cigarette_butts, plastic_bags, wrappers, homes_powered) |> 
  mutate(year = as.character(year),  # Convert year to character for consistency
         source = "Gwynnda")
```


Combine all datasets into one tidy dataset
```{r}
Combined_Trashwheel = bind_rows(Mr_Trashwheel, Professor_Trashwheel, Gwynnda_Trashwheel)
glimpse(Combined_Trashwheel)

```


Total weight of trash collected by Professor Trash Wheel
```{r}
total_weight_professor = Combined_Trashwheel |> 
  filter(source == "Professor Trash Wheel") |> 
  summarise(Total_Weight_Tons = sum(weight_tons, na.rm = TRUE))

total_weight_professor
```


Total cigarette butts collected by Gwynnda in June 2022
```{r}

total_cig_butts_gwynnda = Combined_Trashwheel |> 
  filter(source == "Gwynnda", year == "2022", month == "June") |> 
  summarise(Total_Cigarette_Butts = sum(cigarette_butts, na.rm = TRUE))
total_cig_butts_gwynnda
```


"The combined dataset has **`r nrow(Combined_Trashwheel)`** observations. It includes key variables like total weight of trash (`weight_tons`), number of plastic bottles (`plastic_bottles`), and cigarette butts (`cigarette_butts`). The total weight of trash collected by Professor Trash Wheel is **`r format(total_weight_professor$Total_Weight_Tons, scientific = FALSE)`** tons. Gwynnda collected **`r format(total_cig_butts_gwynnda$Total_Cigarette_Butts, scientific = FALSE)`** cigarette butts in June 2022."


### Problem 3

```{r}
bakers <- 
  read_csv("data/bakers.csv", na = c("NA", "", ".", "N/A")) |> 
  janitor::clean_names() |> 
  separate(baker_name, into = c("baker", "baker_last_name"), sep = " ") |> 
  arrange(series)

```

```{r}
bakes <- 
  read_csv("data/bakes.csv", na = c("NA", "", ".", "N/A")) |> 
  janitor::clean_names() |> 
  mutate(baker = str_replace_all(baker, '"Jo"', "Jo"))

```

```{r}
results <- 
  read_csv("data/results.csv", na = c("NA", "", ".", "N/A"), skip = 2) |> 
  janitor::clean_names() |> 
  mutate(baker = if_else(baker == "Joanne", "Jo", baker))

```



```{r}
# Check for discrepancies
missing_bakes <- anti_join(bakers, bakes)
missing_results <- anti_join(bakers, results, by = "baker")

```


```{r}
# Join the bakes and results datasets
results_and_bakes <- 
  left_join(bakes, results, by = c("baker", "series", "episode"))

# Join with the bakers dataset
final_dataset <- 
  left_join(results_and_bakes, bakers, by = c("baker", "series")) |> 
  relocate(series, episode, baker, baker_last_name, baker_age, baker_occupation, hometown)

```


```{r}
# Export the final dataset
write_csv(final_dataset, "data/final_bakeoff_dataset.csv")

```




```{r}
#Filter for Seasons 5 to 10 and Specific Results
winners <- 
  results |> 
  filter(series <= 10, series >= 5) |> 
  filter(result %in% c("WINNER", "STAR BAKER")) |> 
  select(series, episode, baker, result)

#Pivot the Data to Show Results by Series
winners |> 
  pivot_wider(
    names_from = series,   # Create columns for each series (5-10)
    values_from = baker    # Populate the columns with the baker names
  ) |> 
  arrange(episode) |>      # Arrange by episode
  knitr::kable()           # Create a nicely formatted table

```



Viewership Data

Import the views dataset
```{r viewers_data}
# read data and display first 10 rows
viewers = read_csv('data/viewers.csv') |>
  janitor::clean_names()
head(viewers, 10)
```

Show the first 10 rows of the viewership data
```{r}
viewers |> 
  head(10) |> 
  knitr::kable()  # Optional: Use knitr::kable() for table formatting

```


- average viewership of series 1: `r mean(pull(viewers, series_1), na.rm=TRUE)`

- average viewership of series 5: `r mean(pull(viewers, series_5), na.rm=TRUE)`

